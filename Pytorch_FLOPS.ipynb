{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43224eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9588091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 97.8M/97.8M [00:02<00:00, 40.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "net = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1ce6fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_model_complexity_info(model, input_res,\n",
    "                              print_per_layer_stat=True,\n",
    "                              as_strings=True,\n",
    "                              input_constructor=None, ost=sys.stdout,\n",
    "                              verbose=False, ignore_modules=[]):\n",
    "    assert type(input_res) is tuple\n",
    "    assert len(input_res) >= 2\n",
    "    flops_model = add_flops_counting_methods(model)\n",
    "    flops_model.eval()\n",
    "    flops_model.start_flops_count(ost=ost, verbose=verbose, ignore_list=ignore_modules)\n",
    "    if input_constructor:\n",
    "        input = input_constructor(input_res)\n",
    "        _ = flops_model(**input)\n",
    "    else:\n",
    "        try:\n",
    "            batch = torch.ones(()).new_empty((1, *input_res),\n",
    "                                             dtype=next(flops_model.parameters()).dtype,\n",
    "                                             device=next(flops_model.parameters()).device)\n",
    "        except StopIteration:\n",
    "            batch = torch.ones(()).new_empty((1, *input_res))\n",
    "\n",
    "        _ = flops_model(batch)\n",
    "\n",
    "    flops_count, params_count = flops_model.compute_average_flops_cost()\n",
    "    if print_per_layer_stat:\n",
    "        print_model_with_flops(flops_model, flops_count, params_count, ost=ost)\n",
    "    flops_model.stop_flops_count()\n",
    "\n",
    "    if as_strings:\n",
    "        return flops_to_string(flops_count), params_to_string(params_count)\n",
    "\n",
    "    return flops_count, params_count\n",
    "\n",
    "\n",
    "def flops_to_string(flops, units='GMac', precision=2):\n",
    "    if units is None:\n",
    "        if flops // 10**9 > 0:\n",
    "            return str(round(flops / 10.**9, precision)) + ' GMac'\n",
    "        elif flops // 10**6 > 0:\n",
    "            return str(round(flops / 10.**6, precision)) + ' MMac'\n",
    "        elif flops // 10**3 > 0:\n",
    "            return str(round(flops / 10.**3, precision)) + ' KMac'\n",
    "        else:\n",
    "            return str(flops) + ' Mac'\n",
    "    else:\n",
    "        if units == 'GMac':\n",
    "            return str(round(flops / 10.**9, precision)) + ' ' + units\n",
    "        elif units == 'MMac':\n",
    "            return str(round(flops / 10.**6, precision)) + ' ' + units\n",
    "        elif units == 'KMac':\n",
    "            return str(round(flops / 10.**3, precision)) + ' ' + units\n",
    "        else:\n",
    "            return str(flops) + ' Mac'\n",
    "\n",
    "\n",
    "def params_to_string(params_num, units=None, precision=2):\n",
    "    if units is None:\n",
    "        if params_num // 10 ** 6 > 0:\n",
    "            return str(round(params_num / 10 ** 6, 2)) + ' M'\n",
    "        elif params_num // 10 ** 3:\n",
    "            return str(round(params_num / 10 ** 3, 2)) + ' k'\n",
    "        else:\n",
    "            return str(params_num)\n",
    "    else:\n",
    "        if units == 'M':\n",
    "            return str(round(params_num / 10.**6, precision)) + ' ' + units\n",
    "        elif units == 'K':\n",
    "            return str(round(params_num / 10.**3, precision)) + ' ' + units\n",
    "        else:\n",
    "            return str(params_num)\n",
    "\n",
    "\n",
    "def print_model_with_flops(model, total_flops, total_params, units='GMac',\n",
    "                           precision=3, ost=sys.stdout):\n",
    "\n",
    "    def accumulate_params(self):\n",
    "        if is_supported_instance(self):\n",
    "            return self.__params__\n",
    "        else:\n",
    "            sum = 0\n",
    "            for m in self.children():\n",
    "                sum += m.accumulate_params()\n",
    "            return sum\n",
    "\n",
    "    def accumulate_flops(self):\n",
    "        if is_supported_instance(self):\n",
    "            return self.__flops__ / model.__batch_counter__\n",
    "        else:\n",
    "            sum = 0\n",
    "            for m in self.children():\n",
    "                sum += m.accumulate_flops()\n",
    "            return sum\n",
    "\n",
    "    def flops_repr(self):\n",
    "        accumulated_params_num = self.accumulate_params()\n",
    "        accumulated_flops_cost = self.accumulate_flops()\n",
    "        return ', '.join([params_to_string(accumulated_params_num, units='M', precision=precision),\n",
    "                          '{:.3%} Params'.format(accumulated_params_num / total_params),\n",
    "                          flops_to_string(accumulated_flops_cost, units=units, precision=precision),\n",
    "                          '{:.3%} MACs'.format(accumulated_flops_cost / total_flops),\n",
    "                          self.original_extra_repr()])\n",
    "\n",
    "    def add_extra_repr(m):\n",
    "        m.accumulate_flops = accumulate_flops.__get__(m)\n",
    "        m.accumulate_params = accumulate_params.__get__(m)\n",
    "        flops_extra_repr = flops_repr.__get__(m)\n",
    "        if m.extra_repr != flops_extra_repr:\n",
    "            m.original_extra_repr = m.extra_repr\n",
    "            m.extra_repr = flops_extra_repr\n",
    "            assert m.extra_repr != m.original_extra_repr\n",
    "\n",
    "    def del_extra_repr(m):\n",
    "        if hasattr(m, 'original_extra_repr'):\n",
    "            m.extra_repr = m.original_extra_repr\n",
    "            del m.original_extra_repr\n",
    "        if hasattr(m, 'accumulate_flops'):\n",
    "            del m.accumulate_flops\n",
    "\n",
    "    model.apply(add_extra_repr)\n",
    "    print(model, file=ost)\n",
    "    model.apply(del_extra_repr)\n",
    "\n",
    "\n",
    "def get_model_parameters_number(model):\n",
    "    params_num = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return params_num\n",
    "\n",
    "\n",
    "def add_flops_counting_methods(net_main_module):\n",
    "    # adding additional methods to the existing module object,\n",
    "    # this is done this way so that each function has access to self object\n",
    "    net_main_module.start_flops_count = start_flops_count.__get__(net_main_module)\n",
    "    net_main_module.stop_flops_count = stop_flops_count.__get__(net_main_module)\n",
    "    net_main_module.reset_flops_count = reset_flops_count.__get__(net_main_module)\n",
    "    net_main_module.compute_average_flops_cost = compute_average_flops_cost.__get__(net_main_module)\n",
    "\n",
    "    net_main_module.reset_flops_count()\n",
    "\n",
    "    # Adding variables necessary for masked flops computation\n",
    "    net_main_module.apply(add_flops_mask_variable_or_reset)\n",
    "\n",
    "    return net_main_module\n",
    "\n",
    "\n",
    "def compute_average_flops_cost(self):\n",
    "    \"\"\"\n",
    "    A method that will be available after add_flops_counting_methods() is called\n",
    "    on a desired net object.\n",
    "    Returns current mean flops consumption per image.\n",
    "    \"\"\"\n",
    "\n",
    "    batches_count = self.__batch_counter__\n",
    "    flops_sum = 0\n",
    "    params_sum = 0\n",
    "    for module in self.modules():\n",
    "        if is_supported_instance(module):\n",
    "            flops_sum += module.__flops__\n",
    "            params_sum += module.__params__\n",
    "\n",
    "    return flops_sum / batches_count, params_sum\n",
    "\n",
    "\n",
    "def start_flops_count(self, **kwargs):\n",
    "    \"\"\"\n",
    "    A method that will be available after add_flops_counting_methods() is called\n",
    "    on a desired net object.\n",
    "    Activates the computation of mean flops consumption per image.\n",
    "    Call it before you run the network.\n",
    "    \"\"\"\n",
    "    add_batch_counter_hook_function(self)\n",
    "\n",
    "    seen_types = set()\n",
    "    def add_flops_counter_hook_function(module, ost, verbose, ignore_list):\n",
    "        if type(module) in ignore_list:\n",
    "            seen_types.add(type(module))\n",
    "            if is_supported_instance(module):\n",
    "                module.__params__ = 0\n",
    "        elif is_supported_instance(module):\n",
    "            if hasattr(module, '__flops_handle__'):\n",
    "                return\n",
    "            handle = module.register_forward_hook(MODULES_MAPPING[type(module)])\n",
    "            module.__flops_handle__ = handle\n",
    "            seen_types.add(type(module))\n",
    "        else:\n",
    "            if verbose and not type(module) in (nn.Sequential, nn.ModuleList) and not type(module) in seen_types:\n",
    "                print('Warning: module ' + type(module).__name__ + ' is treated as a zero-op.', file=ost)\n",
    "            seen_types.add(type(module))\n",
    "\n",
    "    self.apply(partial(add_flops_counter_hook_function, **kwargs))\n",
    "\n",
    "\n",
    "def stop_flops_count(self):\n",
    "    \"\"\"\n",
    "    A method that will be available after add_flops_counting_methods() is called\n",
    "    on a desired net object.\n",
    "    Stops computing the mean flops consumption per image.\n",
    "    Call whenever you want to pause the computation.\n",
    "    \"\"\"\n",
    "    remove_batch_counter_hook_function(self)\n",
    "    self.apply(remove_flops_counter_hook_function)\n",
    "\n",
    "\n",
    "def reset_flops_count(self):\n",
    "    \"\"\"\n",
    "    A method that will be available after add_flops_counting_methods() is called\n",
    "    on a desired net object.\n",
    "    Resets statistics computed so far.\n",
    "    \"\"\"\n",
    "    add_batch_counter_variables_or_reset(self)\n",
    "    self.apply(add_flops_counter_variable_or_reset)\n",
    "\n",
    "\n",
    "def add_flops_mask(module, mask):\n",
    "    def add_flops_mask_func(module):\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            module.__mask__ = mask\n",
    "    module.apply(add_flops_mask_func)\n",
    "\n",
    "\n",
    "def remove_flops_mask(module):\n",
    "    module.apply(add_flops_mask_variable_or_reset)\n",
    "\n",
    "\n",
    "# ---- Internal functions\n",
    "def empty_flops_counter_hook(module, input, output):\n",
    "    module.__flops__ += 0\n",
    "\n",
    "\n",
    "def upsample_flops_counter_hook(module, input, output):\n",
    "    output_size = output[0]\n",
    "    batch_size = output_size.shape[0]\n",
    "    output_elements_count = batch_size\n",
    "    for val in output_size.shape[1:]:\n",
    "        output_elements_count *= val\n",
    "    module.__flops__ += int(output_elements_count)\n",
    "\n",
    "\n",
    "def relu_flops_counter_hook(module, input, output):\n",
    "    active_elements_count = output.numel()\n",
    "    module.__flops__ += int(active_elements_count)\n",
    "\n",
    "\n",
    "def linear_flops_counter_hook(module, input, output):\n",
    "    input = input[0]\n",
    "    output_last_dim = output.shape[-1]  # pytorch checks dimensions, so here we don't care much\n",
    "    module.__flops__ += int(np.prod(input.shape) * output_last_dim)\n",
    "\n",
    "\n",
    "def pool_flops_counter_hook(module, input, output):\n",
    "    input = input[0]\n",
    "    module.__flops__ += int(np.prod(input.shape))\n",
    "\n",
    "\n",
    "def bn_flops_counter_hook(module, input, output):\n",
    "    module.affine\n",
    "    input = input[0]\n",
    "\n",
    "    batch_flops = np.prod(input.shape)\n",
    "    if module.affine:\n",
    "        batch_flops *= 2\n",
    "    module.__flops__ += int(batch_flops)\n",
    "\n",
    "\n",
    "def deconv_flops_counter_hook(conv_module, input, output):\n",
    "    # Can have multiple inputs, getting the first one\n",
    "    input = input[0]\n",
    "\n",
    "    batch_size = input.shape[0]\n",
    "    input_height, input_width = input.shape[2:]\n",
    "\n",
    "    kernel_height, kernel_width = conv_module.kernel_size\n",
    "    in_channels = conv_module.in_channels\n",
    "    out_channels = conv_module.out_channels\n",
    "    groups = conv_module.groups\n",
    "\n",
    "    filters_per_channel = out_channels // groups\n",
    "    conv_per_position_flops = kernel_height * kernel_width * in_channels * filters_per_channel\n",
    "\n",
    "    active_elements_count = batch_size * input_height * input_width\n",
    "    overall_conv_flops = conv_per_position_flops * active_elements_count\n",
    "    bias_flops = 0\n",
    "    if conv_module.bias is not None:\n",
    "        output_height, output_width = output.shape[2:]\n",
    "        bias_flops = out_channels * batch_size * output_height * output_height\n",
    "    overall_flops = overall_conv_flops + bias_flops\n",
    "\n",
    "    conv_module.__flops__ += int(overall_flops)\n",
    "\n",
    "\n",
    "def conv_flops_counter_hook(conv_module, input, output):\n",
    "    # Can have multiple inputs, getting the first one\n",
    "    input = input[0]\n",
    "\n",
    "    batch_size = input.shape[0]\n",
    "    output_dims = list(output.shape[2:])\n",
    "\n",
    "    kernel_dims = list(conv_module.kernel_size)\n",
    "    in_channels = conv_module.in_channels\n",
    "    out_channels = conv_module.out_channels\n",
    "    groups = conv_module.groups\n",
    "\n",
    "    filters_per_channel = out_channels // groups\n",
    "    conv_per_position_flops = np.prod(kernel_dims) * in_channels * filters_per_channel\n",
    "\n",
    "    active_elements_count = batch_size * np.prod(output_dims)\n",
    "\n",
    "    if conv_module.__mask__ is not None:\n",
    "        # (b, 1, h, w)\n",
    "        flops_mask = conv_module.__mask__.expand(batch_size, 1, output_height, output_width)\n",
    "        active_elements_count = flops_mask.sum()\n",
    "\n",
    "    overall_conv_flops = conv_per_position_flops * active_elements_count\n",
    "\n",
    "    bias_flops = 0\n",
    "\n",
    "    if conv_module.bias is not None:\n",
    "\n",
    "        bias_flops = out_channels * active_elements_count\n",
    "\n",
    "    overall_flops = overall_conv_flops + bias_flops\n",
    "\n",
    "    conv_module.__flops__ += int(overall_flops)\n",
    "\n",
    "\n",
    "def batch_counter_hook(module, input, output):\n",
    "    batch_size = 1\n",
    "    if len(input) > 0:\n",
    "        # Can have multiple inputs, getting the first one\n",
    "        input = input[0]\n",
    "        batch_size = len(input)\n",
    "    else:\n",
    "        pass\n",
    "        print('Warning! No positional inputs found for a module, assuming batch size is 1.')\n",
    "    module.__batch_counter__ += batch_size\n",
    "\n",
    "\n",
    "def add_batch_counter_variables_or_reset(module):\n",
    "\n",
    "    module.__batch_counter__ = 0\n",
    "\n",
    "\n",
    "def add_batch_counter_hook_function(module):\n",
    "    if hasattr(module, '__batch_counter_handle__'):\n",
    "        return\n",
    "\n",
    "    handle = module.register_forward_hook(batch_counter_hook)\n",
    "    module.__batch_counter_handle__ = handle\n",
    "\n",
    "\n",
    "def remove_batch_counter_hook_function(module):\n",
    "    if hasattr(module, '__batch_counter_handle__'):\n",
    "        module.__batch_counter_handle__.remove()\n",
    "        del module.__batch_counter_handle__\n",
    "\n",
    "\n",
    "def add_flops_counter_variable_or_reset(module):\n",
    "    if is_supported_instance(module):\n",
    "        if hasattr(module, '__flops__') or hasattr(module, '__params__'):\n",
    "            print('Warning: variables __flops__ or __params__ are already '\n",
    "                    'defined for the module' + type(module).__name__ +\n",
    "                    ' ptflops can affect your code!')\n",
    "        module.__flops__ = 0\n",
    "        module.__params__ = get_model_parameters_number(module)\n",
    "\n",
    "\n",
    "MODULES_MAPPING = {\n",
    "    # convolutions\n",
    "    torch.nn.Conv1d: conv_flops_counter_hook,\n",
    "    torch.nn.Conv2d: conv_flops_counter_hook,\n",
    "    torch.nn.Conv3d: conv_flops_counter_hook,\n",
    "    # activations\n",
    "    torch.nn.ReLU: relu_flops_counter_hook,\n",
    "    torch.nn.PReLU: relu_flops_counter_hook,\n",
    "    torch.nn.ELU: relu_flops_counter_hook,\n",
    "    torch.nn.LeakyReLU: relu_flops_counter_hook,\n",
    "    torch.nn.ReLU6: relu_flops_counter_hook,\n",
    "    # poolings\n",
    "    torch.nn.MaxPool1d: pool_flops_counter_hook,\n",
    "    torch.nn.AvgPool1d: pool_flops_counter_hook,\n",
    "    torch.nn.AvgPool2d: pool_flops_counter_hook,\n",
    "    torch.nn.MaxPool2d: pool_flops_counter_hook,\n",
    "    torch.nn.MaxPool3d: pool_flops_counter_hook,\n",
    "    torch.nn.AvgPool3d: pool_flops_counter_hook,\n",
    "    nn.AdaptiveMaxPool1d: pool_flops_counter_hook,\n",
    "    nn.AdaptiveAvgPool1d: pool_flops_counter_hook,\n",
    "    nn.AdaptiveMaxPool2d: pool_flops_counter_hook,\n",
    "    nn.AdaptiveAvgPool2d: pool_flops_counter_hook,\n",
    "    nn.AdaptiveMaxPool3d: pool_flops_counter_hook,\n",
    "    nn.AdaptiveAvgPool3d: pool_flops_counter_hook,\n",
    "    # BNs\n",
    "    torch.nn.BatchNorm1d: bn_flops_counter_hook,\n",
    "    torch.nn.BatchNorm2d: bn_flops_counter_hook,\n",
    "    torch.nn.BatchNorm3d: bn_flops_counter_hook,\n",
    "    # FC\n",
    "    torch.nn.Linear: linear_flops_counter_hook,\n",
    "    # Upscale\n",
    "    torch.nn.Upsample: upsample_flops_counter_hook,\n",
    "    # Deconvolution\n",
    "    torch.nn.ConvTranspose2d: deconv_flops_counter_hook,\n",
    "}\n",
    "\n",
    "\n",
    "def is_supported_instance(module):\n",
    "    if type(module) in MODULES_MAPPING:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def remove_flops_counter_hook_function(module):\n",
    "    if is_supported_instance(module):\n",
    "        if hasattr(module, '__flops_handle__'):\n",
    "            module.__flops_handle__.remove()\n",
    "            del module.__flops_handle__\n",
    "# --- Masked flops counting\n",
    "\n",
    "\n",
    "# Also being run in the initialization\n",
    "def add_flops_mask_variable_or_reset(module):\n",
    "    if is_supported_instance(module):\n",
    "        module.__mask__ = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82950b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  25.557 M, 100.000% Params, 4.122 GMac, 100.000% MACs, \n",
      "  (conv1): Conv2d(0.009 M, 0.037% Params, 0.118 GMac, 2.863% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(0.0 M, 0.001% Params, 0.002 GMac, 0.039% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.019% MACs, inplace=True)\n",
      "  (maxpool): MaxPool2d(0.0 M, 0.000% Params, 0.001 GMac, 0.019% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    0.216 M, 0.844% Params, 0.68 GMac, 16.507% MACs, \n",
      "    (0): Bottleneck(\n",
      "      0.075 M, 0.293% Params, 0.236 GMac, 5.736% MACs, \n",
      "      (conv1): Conv2d(0.004 M, 0.016% Params, 0.013 GMac, 0.312% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(0.037 M, 0.144% Params, 0.116 GMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(0.016 M, 0.064% Params, 0.051 GMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(0.001 M, 0.002% Params, 0.002 GMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.029% MACs, inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        0.017 M, 0.066% Params, 0.053 GMac, 1.285% MACs, \n",
      "        (0): Conv2d(0.016 M, 0.064% Params, 0.051 GMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(0.001 M, 0.002% Params, 0.002 GMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      0.07 M, 0.275% Params, 0.222 GMac, 5.385% MACs, \n",
      "      (conv1): Conv2d(0.016 M, 0.064% Params, 0.051 GMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(0.037 M, 0.144% Params, 0.116 GMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(0.016 M, 0.064% Params, 0.051 GMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(0.001 M, 0.002% Params, 0.002 GMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.029% MACs, inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      0.07 M, 0.275% Params, 0.222 GMac, 5.385% MACs, \n",
      "      (conv1): Conv2d(0.016 M, 0.064% Params, 0.051 GMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(0.037 M, 0.144% Params, 0.116 GMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(0.016 M, 0.064% Params, 0.051 GMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(0.001 M, 0.002% Params, 0.002 GMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.029% MACs, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    1.22 M, 4.772% Params, 1.037 GMac, 25.147% MACs, \n",
      "    (0): Bottleneck(\n",
      "      0.379 M, 1.484% Params, 0.376 GMac, 9.122% MACs, \n",
      "      (conv1): Conv2d(0.033 M, 0.128% Params, 0.103 GMac, 2.493% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(0.0 M, 0.001% Params, 0.001 GMac, 0.019% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(0.147 M, 0.577% Params, 0.116 GMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(0.066 M, 0.256% Params, 0.051 GMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(0.001 M, 0.004% Params, 0.001 GMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.022% MACs, inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        0.132 M, 0.517% Params, 0.104 GMac, 2.512% MACs, \n",
      "        (0): Conv2d(0.131 M, 0.513% Params, 0.103 GMac, 2.493% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(0.001 M, 0.004% Params, 0.001 GMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      0.28 M, 1.096% Params, 0.22 GMac, 5.341% MACs, \n",
      "      (conv1): Conv2d(0.066 M, 0.256% Params, 0.051 GMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(0.147 M, 0.577% Params, 0.116 GMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(0.066 M, 0.256% Params, 0.051 GMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(0.001 M, 0.004% Params, 0.001 GMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.015% MACs, inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      0.28 M, 1.096% Params, 0.22 GMac, 5.341% MACs, \n",
      "      (conv1): Conv2d(0.066 M, 0.256% Params, 0.051 GMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(0.147 M, 0.577% Params, 0.116 GMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(0.066 M, 0.256% Params, 0.051 GMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(0.001 M, 0.004% Params, 0.001 GMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.015% MACs, inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      0.28 M, 1.096% Params, 0.22 GMac, 5.341% MACs, \n",
      "      (conv1): Conv2d(0.066 M, 0.256% Params, 0.051 GMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(0.147 M, 0.577% Params, 0.116 GMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(0.066 M, 0.256% Params, 0.051 GMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(0.001 M, 0.004% Params, 0.001 GMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.015% MACs, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    7.098 M, 27.775% Params, 1.471 GMac, 35.678% MACs, \n",
      "    (0): Bottleneck(\n",
      "      1.512 M, 5.918% Params, 0.374 GMac, 9.080% MACs, \n",
      "      (conv1): Conv2d(0.131 M, 0.513% Params, 0.103 GMac, 2.493% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(0.001 M, 0.002% Params, 0.0 GMac, 0.010% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(0.59 M, 2.308% Params, 0.116 GMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(0.001 M, 0.002% Params, 0.0 GMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(0.262 M, 1.026% Params, 0.051 GMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(0.002 M, 0.008% Params, 0.0 GMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.011% MACs, inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        0.526 M, 2.059% Params, 0.103 GMac, 2.503% MACs, \n",
      "        (0): Conv2d(0.524 M, 2.051% Params, 0.103 GMac, 2.493% MACs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(0.002 M, 0.008% Params, 0.0 GMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      1.117 M, 4.371% Params, 0.219 GMac, 5.320% MACs, \n",
      "      (conv1): Conv2d(0.262 M, 1.026% Params, 0.051 GMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(0.001 M, 0.002% Params, 0.0 GMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(0.59 M, 2.308% Params, 0.116 GMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(0.001 M, 0.002% Params, 0.0 GMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(0.262 M, 1.026% Params, 0.051 GMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(0.002 M, 0.008% Params, 0.0 GMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.007% MACs, inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      1.117 M, 4.371% Params, 0.219 GMac, 5.320% MACs, \n",
      "      (conv1): Conv2d(0.262 M, 1.026% Params, 0.051 GMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(0.001 M, 0.002% Params, 0.0 GMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(0.59 M, 2.308% Params, 0.116 GMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(0.001 M, 0.002% Params, 0.0 GMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(0.262 M, 1.026% Params, 0.051 GMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(0.002 M, 0.008% Params, 0.0 GMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.007% MACs, inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      1.117 M, 4.371% Params, 0.219 GMac, 5.320% MACs, \n",
      "      (conv1): Conv2d(0.262 M, 1.026% Params, 0.051 GMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(0.001 M, 0.002% Params, 0.0 GMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(0.59 M, 2.308% Params, 0.116 GMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(0.001 M, 0.002% Params, 0.0 GMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(0.262 M, 1.026% Params, 0.051 GMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(0.002 M, 0.008% Params, 0.0 GMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.007% MACs, inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      1.117 M, 4.371% Params, 0.219 GMac, 5.320% MACs, \n",
      "      (conv1): Conv2d(0.262 M, 1.026% Params, 0.051 GMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(0.001 M, 0.002% Params, 0.0 GMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(0.59 M, 2.308% Params, 0.116 GMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(0.001 M, 0.002% Params, 0.0 GMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(0.262 M, 1.026% Params, 0.051 GMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(0.002 M, 0.008% Params, 0.0 GMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.007% MACs, inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      1.117 M, 4.371% Params, 0.219 GMac, 5.320% MACs, \n",
      "      (conv1): Conv2d(0.262 M, 1.026% Params, 0.051 GMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(0.001 M, 0.002% Params, 0.0 GMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(0.59 M, 2.308% Params, 0.116 GMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(0.001 M, 0.002% Params, 0.0 GMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(0.262 M, 1.026% Params, 0.051 GMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(0.002 M, 0.008% Params, 0.0 GMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.007% MACs, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    14.965 M, 58.554% Params, 0.811 GMac, 19.676% MACs, \n",
      "    (0): Bottleneck(\n",
      "      6.04 M, 23.632% Params, 0.373 GMac, 9.059% MACs, \n",
      "      (conv1): Conv2d(0.524 M, 2.051% Params, 0.103 GMac, 2.493% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(0.001 M, 0.004% Params, 0.0 GMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2.359 M, 9.231% Params, 0.116 GMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(0.001 M, 0.004% Params, 0.0 GMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1.049 M, 4.103% Params, 0.051 GMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(0.004 M, 0.016% Params, 0.0 GMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.005% MACs, inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        2.101 M, 8.222% Params, 0.103 GMac, 2.498% MACs, \n",
      "        (0): Conv2d(2.097 M, 8.206% Params, 0.103 GMac, 2.493% MACs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(0.004 M, 0.016% Params, 0.0 GMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      4.463 M, 17.461% Params, 0.219 GMac, 5.309% MACs, \n",
      "      (conv1): Conv2d(1.049 M, 4.103% Params, 0.051 GMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(0.001 M, 0.004% Params, 0.0 GMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2.359 M, 9.231% Params, 0.116 GMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(0.001 M, 0.004% Params, 0.0 GMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1.049 M, 4.103% Params, 0.051 GMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(0.004 M, 0.016% Params, 0.0 GMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.004% MACs, inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      4.463 M, 17.461% Params, 0.219 GMac, 5.309% MACs, \n",
      "      (conv1): Conv2d(1.049 M, 4.103% Params, 0.051 GMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(0.001 M, 0.004% Params, 0.0 GMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2.359 M, 9.231% Params, 0.116 GMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(0.001 M, 0.004% Params, 0.0 GMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1.049 M, 4.103% Params, 0.051 GMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(0.004 M, 0.016% Params, 0.0 GMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.004% MACs, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.0 GMac, 0.002% MACs, output_size=(1, 1))\n",
      "  (fc): Linear(2.049 M, 8.017% Params, 0.002 GMac, 0.050% MACs, in_features=2048, out_features=1000, bias=True)\n",
      ")\n",
      "Computational complexity:       4.12 GMac\n",
      "Number of parameters:           25.56 M \n"
     ]
    }
   ],
   "source": [
    "flops, params = get_model_complexity_info(net, (3, 224, 224),\n",
    "                                              as_strings=True,\n",
    "                                              print_per_layer_stat=True)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', flops))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d7a71e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
